{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_to_ONNX.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCLXQDh0RLaeCSiWGiN5b4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba0322bd609440cba83b08a840d672e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_159282b9281f4ff5acc1817e66667556",
              "IPY_MODEL_9c3de913c31e4d05a1bb6e9619880f76",
              "IPY_MODEL_09df8e75a97e4ec08c78832ec9e6ea64"
            ],
            "layout": "IPY_MODEL_2bd96d4809274e7092dcf1be7203b62b"
          }
        },
        "159282b9281f4ff5acc1817e66667556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb7acdbb7f145ccbbf3463472122506",
            "placeholder": "​",
            "style": "IPY_MODEL_999836588f0b4c8b83233547fd6ba8f0",
            "value": "100%"
          }
        },
        "9c3de913c31e4d05a1bb6e9619880f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8991e1560dbb4c3a8953f1f167671652",
            "max": 110559176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5037d5fd8c8b4983b4a58186ac9f989e",
            "value": 110559176
          }
        },
        "09df8e75a97e4ec08c78832ec9e6ea64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cd94934844d4a6f9381ccc97069ca57",
            "placeholder": "​",
            "style": "IPY_MODEL_75c1515dd81044e3bdb90d04c6aa63ad",
            "value": " 105M/105M [05:10&lt;00:00, 358kB/s]"
          }
        },
        "2bd96d4809274e7092dcf1be7203b62b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb7acdbb7f145ccbbf3463472122506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999836588f0b4c8b83233547fd6ba8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8991e1560dbb4c3a8953f1f167671652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5037d5fd8c8b4983b4a58186ac9f989e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cd94934844d4a6f9381ccc97069ca57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c1515dd81044e3bdb90d04c6aa63ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mosovam/react-medical-view/blob/main/Model_to_ONNX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/8c7f0be1e1c3803fcb4c41bcd9f4226b/super_resolution_with_onnxruntime.ipynb\n",
        "\n",
        "https://pytorch.org/docs/master/onnx.html#example-alexnet-from-pytorch-to-onnx"
      ],
      "metadata": {
        "id": "g0-4SDy3Rm4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UXJcj5lTocm",
        "outputId": "312f85cc-d6e9-4f1c-ad7c-6281378fed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.2.1-py3-none-any.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n",
            "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models-pytorch) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (1.10.0+cu111)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=daf34d6c9e12efc201779b3bbc615ef47d24949dde2200222964f682162e097c\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=8fc8cf662b090c6dfb46501a3c0e99585765791f8402873db82695eb65316dc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.1 timm-0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some standard imports\n",
        "import io\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx"
      ],
      "metadata": {
        "id": "k7jTI6m4RovH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the files from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoDoCRxlS_ld",
        "outputId": "8336dad5-f1e8-4052-917e-852650420e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER_PATH = '/content/drive/MyDrive/OSU_IT/BC_MMO'\n",
        "ENCODER = 'se_resnext50_32x4d'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "DEVICE = 'cuda'\n",
        "CLASSES = ['tumor', 'unlabelled']\n",
        "\n",
        "my_model = smp.Unet(\n",
        "    encoder_name=ENCODER, \n",
        "    encoder_weights=ENCODER_WEIGHTS, \n",
        "    classes=len(CLASSES), \n",
        "    activation=ACTIVATION\n",
        ")"
      ],
      "metadata": {
        "id": "nzvVInvPTEjp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ba0322bd609440cba83b08a840d672e1",
            "159282b9281f4ff5acc1817e66667556",
            "9c3de913c31e4d05a1bb6e9619880f76",
            "09df8e75a97e4ec08c78832ec9e6ea64",
            "2bd96d4809274e7092dcf1be7203b62b",
            "3fb7acdbb7f145ccbbf3463472122506",
            "999836588f0b4c8b83233547fd6ba8f0",
            "8991e1560dbb4c3a8953f1f167671652",
            "5037d5fd8c8b4983b4a58186ac9f989e",
            "3cd94934844d4a6f9381ccc97069ca57",
            "75c1515dd81044e3bdb90d04c6aa63ad"
          ]
        },
        "outputId": "a261ca97-38ac-43ce-e05d-b4a66aa57a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/105M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba0322bd609440cba83b08a840d672e1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = FOLDER_PATH + '/tumor_model/my_segmentation_model_saved_as_epochs8'\n",
        "\n",
        "my_model.load_state_dict(torch.load(path))\n",
        "my_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht6zGryNVZnR",
        "outputId": "d9ebe66a-c437-4f56-f0c2-f2e62a3ebb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (encoder): SENetEncoder(\n",
              "    (layer0): Sequential(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    )\n",
              "    (layer1): Sequential(\n",
              "      (0): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (2): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (2): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (3): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (2): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (3): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (4): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (5): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (2): SEResNeXtBottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (se_module): SEModule(\n",
              "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (sigmoid): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): UnetDecoder(\n",
              "    (center): Identity()\n",
              "    (blocks): ModuleList(\n",
              "      (0): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): DecoderBlock(\n",
              "        (conv1): Conv2dReLU(\n",
              "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention1): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "        (conv2): Conv2dReLU(\n",
              "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (attention2): Attention(\n",
              "          (attention): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (segmentation_head): SegmentationHead(\n",
              "    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Identity()\n",
              "    (2): Activation(\n",
              "      (activation): Sigmoid()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('Model on cuda!')\n",
        "    my_model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnjourRKXS_a",
        "outputId": "34981b45-093b-401f-b1fe-c05ccc9e3b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model on cuda!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "nXV7W0ekqlxa",
        "outputId": "1da0c6a0-0ac7-443f-a767-950fe476805b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 9            |        cudaMalloc retries: 9         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   10705 MB |   10705 MB |   19322 MB |    8617 MB |\\n|       from large pool |   10658 MB |   10658 MB |   19151 MB |    8493 MB |\\n|       from small pool |      47 MB |      47 MB |     171 MB |     124 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   10705 MB |   10705 MB |   19322 MB |    8617 MB |\\n|       from large pool |   10658 MB |   10658 MB |   19151 MB |    8493 MB |\\n|       from small pool |      47 MB |      47 MB |     171 MB |     124 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   10816 MB |   10816 MB |   10816 MB |       0 B  |\\n|       from large pool |   10768 MB |   10768 MB |   10768 MB |       0 B  |\\n|       from small pool |      48 MB |      48 MB |      48 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  113221 KB |  365512 KB |   10274 MB |   10164 MB |\\n|       from large pool |  112368 KB |  363440 KB |   10089 MB |    9979 MB |\\n|       from small pool |     853 KB |   18468 KB |     185 MB |     184 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    2053    |    2053    |    5234    |    3181    |\\n|       from large pool |     927    |     927    |    1277    |     350    |\\n|       from small pool |    1126    |    1127    |    3957    |    2831    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    2053    |    2053    |    5234    |    3181    |\\n|       from large pool |     927    |     927    |    1277    |     350    |\\n|       from small pool |    1126    |    1127    |    3957    |    2831    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     373    |     373    |     373    |       0    |\\n|       from large pool |     349    |     349    |     349    |       0    |\\n|       from small pool |      24    |      24    |      24    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      85    |     122    |     705    |     620    |\\n|       from large pool |      80    |      87    |     406    |     326    |\\n|       from small pool |       5    |      40    |     299    |     294    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model\n",
        "dummy_input = torch.randn(1, 3, 512, 512, device=\"cuda\")\n",
        "torch.onnx.export(my_model,               # model being run\n",
        "                  dummy_input,               # model input (or a tuple for multiple inputs)\n",
        "                  FOLDER_PATH + \"/brain_tumor_segmentation.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file,\n",
        "                  opset_version=12,          # the ONNX version to export the model to\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkR8p6WBR2ze",
        "outputId": "b5bd79a7-97e5-40ce-85c9-6398e1a68d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:269: UserWarning: `add_node_names' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `add_node_names` argument will be ignored.\n",
            "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:269: UserWarning: `do_constant_folding' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `do_constant_folding` argument will be ignored.\n",
            "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1smhtpfUewsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets git+https://github.com/neuml/txtai#egg=txtai[pipeline]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPgxaJcafhkT",
        "outputId": "2f63c8ea-116f-46dd-fcb3-348c838ae18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting txtai[pipeline]\n",
            "  Cloning https://github.com/neuml/txtai to /tmp/pip-install-0dbq_w1e/txtai_0d3c0cd5b4c94bac97d1540623a1f119\n",
            "  Running command git clone -q https://github.com/neuml/txtai /tmp/pip-install-0dbq_w1e/txtai_0d3c0cd5b4c94bac97d1540623a1f119\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets\n",
            "  Using cached datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "Collecting tokenizers>=0.10.3\n",
            "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Collecting transformers>=4.12.3\n",
            "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from txtai[pipeline]) (1.21.6)\n",
            "Collecting faiss-cpu>=1.7.1.post2\n",
            "  Using cached faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from txtai[pipeline]) (1.10.0+cu111)\n",
            "Collecting pyyaml>=5.3\n",
            "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting beautifulsoup4>=4.9.3\n",
            "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "Collecting imagehash>=4.2.1\n",
            "  Using cached ImageHash-4.2.1.tar.gz (812 kB)\n",
            "Collecting fasttext>=0.9.2\n",
            "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
            "Requirement already satisfied: soundfile>=0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from txtai[pipeline]) (0.10.3.post1)\n",
            "Collecting timm>=0.4.12\n",
            "  Using cached timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "Collecting tika>=1.24\n",
            "  Using cached tika-1.24.tar.gz (28 kB)\n",
            "Collecting nltk>=3.5\n",
            "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from txtai[pipeline]) (1.3.5)\n",
            "Collecting onnxruntime>=1.8.1\n",
            "  Using cached onnxruntime-1.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "Collecting pillow>=9.0.1\n",
            "  Using cached Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting onnx>=1.10.1\n",
            "  Using cached onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "Collecting onnxmltools>=1.9.1\n",
            "  Using cached onnxmltools-1.11.0-py2.py3-none-any.whl (302 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4>=4.9.3->txtai[pipeline]) (2.3.2.post1)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext>=0.9.2->txtai[pipeline]) (2.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext>=0.9.2->txtai[pipeline]) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imagehash>=4.2.1->txtai[pipeline]) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imagehash>=4.2.1->txtai[pipeline]) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash>=4.2.1->txtai[pipeline]) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->txtai[pipeline]) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->txtai[pipeline]) (4.64.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Using cached regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->txtai[pipeline]) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.1->txtai[pipeline]) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.10.1->txtai[pipeline]) (4.1.1)\n",
            "Collecting skl2onnx\n",
            "  Using cached skl2onnx-1.11.1-py3-none-any.whl (276 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->txtai[pipeline]) (2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->txtai[pipeline]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->txtai[pipeline]) (2022.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.3.post1->txtai[pipeline]) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.3.post1->txtai[pipeline]) (2.21)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika>=1.24->txtai[pipeline]) (2.23.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm>=0.4.12->txtai[pipeline]) (0.11.1+cu111)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai[pipeline]) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai[pipeline]) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai[pipeline]) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "Collecting sacremoses\n",
            "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.12.3->txtai[pipeline]) (3.0.8)\n",
            "Collecting xxhash\n",
            "  Using cached xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Using cached aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Using cached fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting responses<0.19\n",
            "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika>=1.24->txtai[pipeline]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika>=1.24->txtai[pipeline]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika>=1.24->txtai[pipeline]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika>=1.24->txtai[pipeline]) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Using cached yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Using cached asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Using cached multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Using cached frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.12.3->txtai[pipeline]) (3.8.0)\n",
            "Collecting onnxconverter-common>=1.7.0\n",
            "  Using cached onnxconverter_common-1.9.0-py2.py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from skl2onnx->onnxmltools>=1.9.1->txtai[pipeline]) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19->skl2onnx->onnxmltools>=1.9.1->txtai[pipeline]) (3.1.0)\n",
            "Building wheels for collected packages: txtai, fasttext, imagehash, tika\n",
            "  Building wheel for txtai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for txtai: filename=txtai-4.4.0-py3-none-any.whl size=134703 sha256=61b0f15806c5bc3b2363de81ca6b68819520773a58aa0af2b1150f4dfeb3305b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9akbumgk/wheels/83/d6/ae/6b41733966092887bf61f691622261d990943588a03e5cd0be\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3143467 sha256=40fc7f165ec9207cf220ad6b05e07668ed4d5e6bfcdb72d168bb52b4df2181f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=1f018aed9ff2778bf9eb360275d9a1ccc915ed803773970dc398761e1893c819\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32893 sha256=979b6002c40b05baf094d29ef504503a54f9de197db8f35207366217ea05e014\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "Successfully built txtai fasttext imagehash tika\n",
            "Installing collected packages: urllib3, regex, pyyaml, onnx, multidict, frozenlist, yarl, tokenizers, sacremoses, pillow, onnxconverter-common, huggingface-hub, asynctest, async-timeout, aiosignal, transformers, skl2onnx, fsspec, faiss-cpu, aiohttp, xxhash, txtai, timm, tika, sentencepiece, responses, onnxruntime, onnxmltools, nltk, imagehash, fasttext, beautifulsoup4, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx as onnx"
      ],
      "metadata": {
        "id": "dejEG3sygCCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4UWDaZffOW",
        "outputId": "28c6c567-0247-4336-d7b2-0876d4eb1bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime"
      ],
      "metadata": {
        "id": "ZJydUlPgkw8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m onnxruntime.tools.convert_onnx_models_to_ort /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAaWd96GkpGA",
        "outputId": "3c4b7c26-3466-4db8-88aa-4cd7aa7d4a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting models with optimization style 'Fixed' and level 'all'\n",
            "Converting optimized ONNX model /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.onnx to ORT format model /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.ort\n",
            "2022-04-19 21:13:01.232040757 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232101182 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232117905 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232133140 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232162165 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232175876 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232190234 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232204607 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232218186 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232232482 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232246109 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232259600 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232273184 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232290649 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232305115 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232319888 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232334769 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232349234 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232363168 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232377366 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232391023 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232404810 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232433636 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232460039 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232475522 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232490099 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232504299 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232525508 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232540356 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232554696 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232569779 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232585187 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232600055 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232614326 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232645079 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232660747 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232677627 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232693209 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232738032 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.232768320 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246247018 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246272759 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246303085 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246334051 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246363600 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246378510 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246392248 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246406234 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246420445 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246462718 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246493441 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246509063 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246533449 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246544367 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246581955 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246601083 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246611457 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.246621319 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248876198 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248915790 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248932552 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248948020 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248963373 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248979645 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.248995730 [W:onnxruntime:, graph.cc:1271 Graph] Initializer segmentation_head.0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249013463 [W:onnxruntime:, graph.cc:1271 Graph] Initializer segmentation_head.0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249030891 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 775 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249046947 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 776 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249077567 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 778 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249093356 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 779 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249109186 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 781 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249125666 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 782 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249156204 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 784 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249187443 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 785 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249218216 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 787 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249234322 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 788 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249250708 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 790 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249267751 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 791 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249287188 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 793 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249305031 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 794 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249321509 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 796 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249348498 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 797 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249367685 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 799 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249384704 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 800 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249400413 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 802 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249430594 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 803 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249478385 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 805 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249496925 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 806 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249550053 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 808 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249567014 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 809 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249577858 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 811 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249594250 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 812 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249611446 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 814 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249629383 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 815 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249647225 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 817 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.249665515 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 818 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350288643 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 820 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350322378 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 821 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350354658 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 823 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350371472 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 824 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350389092 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 826 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350405870 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 827 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350421998 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 829 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350456438 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 830 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350475798 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 832 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.350492294 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 833 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351000835 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 835 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351037216 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 836 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351056209 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 838 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351074518 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 839 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351091834 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 841 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351108713 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 842 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351125407 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 844 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351141887 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 845 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351159352 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 847 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351176314 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 848 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351480267 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 850 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351500215 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 851 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351515588 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 853 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351530252 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 854 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351543818 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 856 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351557488 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 857 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351571057 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 859 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351585110 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 860 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351599865 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 862 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.351613306 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 863 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352292454 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 865 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352316930 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 866 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352335269 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 868 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352351762 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 869 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352368466 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 871 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352385846 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 872 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352401809 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 874 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352418784 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 875 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352824192 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 877 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352849019 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 878 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352866692 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 880 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352883997 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 881 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352901039 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 883 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352919300 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 884 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352935852 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 886 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352953032 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 887 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352969439 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 889 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.352986291 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 890 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353365658 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 892 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353389753 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 893 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353407989 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 895 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353425534 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 896 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353453174 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 898 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353477159 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 899 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353494191 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 901 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353511576 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 902 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353528435 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 904 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.353544494 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 905 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354155501 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 907 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354180189 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 908 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354197589 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 910 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354214572 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 911 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354231389 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 913 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354248575 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 914 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354264165 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 916 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354280945 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 917 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354310288 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 919 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354326607 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 920 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354342766 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 922 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354359024 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 923 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354380315 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 925 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354397806 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 926 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354428786 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 928 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354456262 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 929 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354477048 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 931 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.354488333 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 932 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355230384 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 934 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355254776 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 935 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355272255 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 937 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355288477 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 938 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355304498 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 940 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355320584 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 941 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355335947 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 943 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355351958 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 944 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355367307 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 946 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355383604 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 947 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355753952 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 949 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355779751 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 950 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355799092 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 952 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355817334 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 953 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355835331 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 955 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355855565 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 956 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355873568 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 958 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355892306 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 959 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355910102 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 961 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:01.355928389 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 962 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "Converted 1/1 models successfully.\n",
            "Generating config file from ORT format models with optimization style 'Fixed' and level 'all'\n",
            "2022-04-19 21:13:03,133 ort_format_model.utils [INFO] - Created config in /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.required_operators.config\n",
            "Converting models with optimization style 'Runtime' and level 'all'\n",
            "Converting optimized ONNX model /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.onnx to ORT format model /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.with_runtime_opt.ort\n",
            "2022-04-19 21:13:03.368586118 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368623571 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368636079 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368650336 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368672043 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368685663 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368701421 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368729160 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368742250 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368755790 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368769031 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368782330 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368795243 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368808264 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368821223 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368834602 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368848523 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368861363 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368874378 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368887753 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368902019 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368915881 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368930944 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368944368 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368957724 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368970793 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368984962 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.368998020 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369017573 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369031993 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369045302 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369058251 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369071392 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369084392 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369097302 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369110133 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369124268 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369137318 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369150581 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.369163938 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402501238 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402540608 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402558202 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402573438 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402587652 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402602553 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402616394 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.402630388 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404148934 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404187815 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404202755 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404217492 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404231237 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404244437 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404257967 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404271097 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404284921 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404299364 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404314248 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404329151 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404342997 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404356577 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404369454 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404382636 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404395996 [W:onnxruntime:, graph.cc:1271 Graph] Initializer segmentation_head.0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404412560 [W:onnxruntime:, graph.cc:1271 Graph] Initializer segmentation_head.0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404427512 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 775 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404445529 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 776 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404459806 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 778 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404474191 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 779 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404489754 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 781 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404503512 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 782 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404536691 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 784 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404552485 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 785 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404564732 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 787 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404577001 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 788 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404589512 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 790 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404603337 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 791 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404618486 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 793 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404633797 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 794 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404646089 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 796 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404691032 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 797 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404707294 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 799 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404736368 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 800 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404798257 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 802 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.404814938 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 803 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504395450 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 805 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504420250 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 806 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504479109 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 808 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504496590 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 809 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504527219 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 811 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504554260 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 812 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504571016 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 814 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504586909 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 815 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504842154 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 817 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504865716 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 818 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504889704 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 820 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504920458 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 821 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504934518 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 823 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504948341 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 824 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504972039 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 826 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.504997917 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 827 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505020270 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 829 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505036099 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 830 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505322034 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 832 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505343070 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 833 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505357700 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 835 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505371755 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 836 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505401378 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 838 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505417897 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 839 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505432185 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 841 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505715442 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 842 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505734725 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 844 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505751772 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 845 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505795127 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 847 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505813077 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 848 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505828546 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 850 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505844087 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 851 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505874480 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 853 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505891930 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 854 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505914480 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 856 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505949868 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 857 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.505964035 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 859 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506216240 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 860 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506260911 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 862 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506278237 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 863 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506292104 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 865 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506315240 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 866 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506330103 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 868 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506344240 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 869 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506365588 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 871 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506381739 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 872 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506396422 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 874 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506660576 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 875 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506704040 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 877 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506720619 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 878 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506734465 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 880 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506748301 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 881 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506772469 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 883 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506788630 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 884 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.506802821 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 886 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507061354 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 887 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507157253 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 889 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507175625 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 890 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507198960 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 892 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507215014 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 893 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507229498 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 895 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507504680 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 896 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507521915 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 898 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507536381 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 899 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507550500 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 901 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507569354 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 902 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507583830 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 904 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507597176 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 905 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507610034 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 907 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507623707 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 908 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507650879 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 910 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507665070 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 911 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507688035 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 913 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507704301 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 914 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.507733019 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 916 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508036629 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 917 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508085094 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 919 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508103749 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 920 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508134146 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 922 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508162801 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 923 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508185568 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 925 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508226935 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 926 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508245037 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 928 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508263194 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 929 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508666125 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 931 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508727806 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 932 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508759978 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 934 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508774679 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 935 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508788665 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 937 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508802238 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 938 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508815012 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 940 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508828918 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 941 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508856708 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 943 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.508886087 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 944 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509251986 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 946 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509280199 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 947 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509303064 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 949 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509334228 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 950 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509349499 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 952 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509389036 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 953 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509406215 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 955 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509427887 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 956 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509444728 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 958 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509460334 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 959 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509852176 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 961 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:03.509889040 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 962 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "Converted 1/1 models successfully.\n",
            "Converting models again without runtime optimizations to generate a complete config file. These converted models are temporary and will be deleted.\n",
            "Converting optimized ONNX model /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.onnx to ORT format model /content/drive/MyDrive/OSU_IT/BC_MMO/tmpx6ra1sl6.without_runtime_opt/brain_tumor_segmentation.ort\n",
            "2022-04-19 21:13:04.444788220 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444828100 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444841513 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444854656 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444875181 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444889173 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444905109 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444921377 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444936826 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444952099 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444968377 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444983639 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer1.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.444998772 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445021025 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445039748 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445052205 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445069417 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445085027 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445099769 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445115698 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445130651 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445147274 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445162449 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445177681 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445192857 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445207824 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445222684 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445237689 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer2.3.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445252855 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445268205 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445283205 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445298363 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445313418 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445328608 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445343434 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445358553 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445374891 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445390163 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445405194 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.445420388 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.516991919 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517024560 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517041920 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517069952 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.3.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517085645 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517098568 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517111814 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517126685 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.4.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.517946881 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518008255 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518026229 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518042948 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer3.5.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518059168 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518076515 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518093674 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518110390 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.0.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518205215 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518226558 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518398787 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518690785 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.1.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518725335 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518742933 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518958511 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518976852 [W:onnxruntime:, graph.cc:1271 Graph] Initializer encoder.layer4.2.se_module.fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.518994052 [W:onnxruntime:, graph.cc:1271 Graph] Initializer segmentation_head.0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519011235 [W:onnxruntime:, graph.cc:1271 Graph] Initializer segmentation_head.0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519033527 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 775 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519055890 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 776 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519077630 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 778 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519094774 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 779 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519202388 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 781 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519222835 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 782 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519240216 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 784 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519257554 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 785 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519274276 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 787 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519292809 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 788 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519309716 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 790 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519326812 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 791 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519345895 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 793 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519629171 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 794 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519652968 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 796 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519671418 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 797 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519696994 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 799 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519716710 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 800 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519735331 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 802 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519753600 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 803 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519771406 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 805 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519804460 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 806 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.519836207 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 808 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520079735 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 809 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520102693 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 811 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520119847 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 812 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520297496 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 814 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520327521 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 815 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520345044 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 817 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520599804 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 818 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520622961 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 820 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520640736 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 821 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520690799 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 823 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520708435 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 824 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520740501 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 826 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520827032 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 827 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520846925 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 829 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520866998 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 830 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520884444 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 832 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520902400 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 833 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520920311 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 835 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520938391 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 836 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520956314 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 838 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.520988321 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 839 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521256405 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 841 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521277410 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 842 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521293720 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 844 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521523520 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 845 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521561526 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 847 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521579396 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 848 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521596438 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 850 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521628162 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 851 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521645514 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 853 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.521662495 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 854 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522037568 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 856 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522065888 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 857 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522083201 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 859 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522176967 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 860 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522195473 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 862 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522212548 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 863 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522228844 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 865 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522245348 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 866 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522262046 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 868 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522274427 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 869 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522790271 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 871 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.522830242 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 872 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523060109 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 874 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523082407 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 875 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523099527 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 877 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523115834 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 878 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523131796 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 880 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523148081 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 881 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523164326 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 883 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523190599 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 884 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523207690 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 886 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523225086 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 887 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523241285 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 889 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523258116 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 890 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523274206 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 892 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523290880 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 893 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523306656 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 895 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523523469 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 896 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.523979038 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 898 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524008280 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 899 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524025964 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 901 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524042435 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 902 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524057415 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 904 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524157673 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 905 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524190261 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 907 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524205975 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 908 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524220800 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 910 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524236231 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 911 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524422771 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 913 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524471791 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 914 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524489863 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 916 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524504860 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 917 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524528963 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 919 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524544953 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 920 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524560042 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 922 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524574691 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 923 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524601803 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 925 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524617425 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 926 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524631833 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 928 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524646489 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 929 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524660845 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 931 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524675005 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 932 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524689791 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 934 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524704854 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 935 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524733932 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 937 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524752872 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 938 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524782975 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 940 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524797112 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 941 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524810425 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 943 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524824652 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 944 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524838352 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 946 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524852125 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 947 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524866495 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 949 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524880791 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 950 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524894659 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 952 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524904871 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 953 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524926794 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 955 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524940495 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 956 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524953654 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 958 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524967473 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 959 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524981354 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 961 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "2022-04-19 21:13:04.524994754 [W:onnxruntime:, graph.cc:1271 Graph] Initializer 962 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
            "Converted 1/1 models successfully.\n",
            "Generating config file from ORT format models with optimization style 'Runtime' and level 'all'\n",
            "2022-04-19 21:13:05,782 ort_format_model.utils [INFO] - Created config in /content/drive/MyDrive/OSU_IT/BC_MMO/brain_tumor_segmentation.required_operators.with_runtime_opt.config\n"
          ]
        }
      ]
    }
  ]
}